{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.ao import quantization as q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470378c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.2069, 0.1993, 0.8558, 0.7171, 0.0387], requires_grad=True)\n",
      "mn: 0.038726806640625\n",
      "mx: 0.8558149337768555\n",
      "scale: 0.0032042672391980886\n",
      "Forward\n",
      "Input:  [0.20688236 0.19932824 0.85581493 0.7171295  0.03872681]\n",
      "Output: [0.20827737 0.19866458 0.40694195 0.40694195 0.03845121]\n",
      "Backward\n",
      "grad: tensor([1., 1., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "zero_point = 0\n",
    "quant_min = -128\n",
    "quant_max = 127\n",
    "\n",
    "x = torch.rand(5)\n",
    "x.requires_grad = True\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "mn = x.min()\n",
    "mx = x.max()\n",
    "scale = ((mx - mn) / (quant_max - quant_min)).item()\n",
    "\n",
    "print(f\"mn: {mn}\")\n",
    "print(f\"mx: {mx}\")\n",
    "print(f\"scale: {scale}\")\n",
    "\n",
    "\n",
    "print(\"Forward\")\n",
    "x_fq = torch.fake_quantize_per_tensor_affine(x, scale, zero_point, quant_min, quant_max)\n",
    "print(f\"Input:  {x.detach().numpy()}\")\n",
    "print(f\"Output: {x_fq.detach().numpy()}\")\n",
    "\n",
    "print(\"Backward\")\n",
    "loss = x_fq.sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"grad: {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34af9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFakeQuantize(nn.Module):\n",
    "    def __init__(self, observer, quant_min=-128, quant_max=127):\n",
    "        super().__init__()\n",
    "        self.observer = observer\n",
    "        self.quant_min = quant_min\n",
    "        self.quant_max = quant_max\n",
    "        self.scale = None\n",
    "        self.zero_point = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            self.observer(x)\n",
    "            self.scale, self.zero_point = self.observer.calculate_qparams()\n",
    "\n",
    "            x_fq = torch.fake_quantize_per_tensor_affine(\n",
    "                x,\n",
    "                scale=self.scale,\n",
    "                zero_point=self.zero_point,\n",
    "                quant_min=self.quant_min,\n",
    "                quant_max=self.quant_max,\n",
    "            )\n",
    "\n",
    "            return x_fq\n",
    "        else:\n",
    "            return torch.fake_quantize_per_tensor_affine(\n",
    "                x, self.scale, self.zero_point, self.quant_min, self.quant_max\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e09f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantConv2d(nn.Module):    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        bias=True,\n",
    "        weight_quant_min=-128,\n",
    "        weight_quant_max=127,\n",
    "        activation_quant_min=0,\n",
    "        activation_quant_max=255,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "        \n",
    "        self.weight_fake_quant = MyFakeQuantize(\n",
    "            observer=q.MinMaxObserver(\n",
    "                dtype=torch.qint8,\n",
    "                qscheme=torch.per_tensor_symmetric,\n",
    "            ),\n",
    "            quant_min=weight_quant_min,\n",
    "            quant_max=weight_quant_max,\n",
    "        )\n",
    "        \n",
    "        self.activation_fake_quant = MyFakeQuantize(\n",
    "            observer=q.MinMaxObserver(\n",
    "                dtype=torch.quint8,\n",
    "                qscheme=torch.per_tensor_affine,\n",
    "            ),\n",
    "            quant_min=activation_quant_min,\n",
    "            quant_max=activation_quant_max,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_quantized = self.activation_fake_quant(x)\n",
    "        \n",
    "        weight_quantized = self.weight_fake_quant(self.conv.weight)\n",
    "        \n",
    "        output = torch.nn.functional.conv2d(\n",
    "            x_quantized,\n",
    "            weight_quantized,\n",
    "            bias=self.conv.bias,\n",
    "            stride=self.conv.stride,\n",
    "            padding=self.conv.padding,\n",
    "        )\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1417a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 32, 32])\n",
      "Output shape: torch.Size([1, 16, 32, 32])\n",
      "Weight scale: tensor([0.0015])\n",
      "Weight zero_point: tensor([0])\n",
      "Activation scale: tensor([0.0285])\n",
      "Activation zero_point: tensor([125], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "qconv = QuantConv2d(\n",
    "    in_channels=3,\n",
    "    out_channels=16,\n",
    "    kernel_size=3,\n",
    "    padding=1,\n",
    ")\n",
    "\n",
    "x_test = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "qconv.train()\n",
    "output_train = qconv(x_test)\n",
    "print(f\"Input shape: {x_test.shape}\")\n",
    "print(f\"Output shape: {output_train.shape}\")\n",
    "print(f\"Weight scale: {qconv.weight_fake_quant.scale}\")\n",
    "print(f\"Weight zero_point: {qconv.weight_fake_quant.zero_point}\")\n",
    "print(f\"Activation scale: {qconv.activation_fake_quant.scale}\")\n",
    "print(f\"Activation zero_point: {qconv.activation_fake_quant.zero_point}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
